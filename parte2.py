# -*- coding: utf-8 -*-
"""parte2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X59jott--cq3MByVRA-XCABPblblSNu6

# 2.A Regresión Y Validación
"""

#librerias
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.pipeline import Pipeline

# Carga de los datos
x_train = np.load("part2xTrain.npy").ravel()
y_train = np.load("part2yTrain.npy").ravel()
x_val = np.load("part2xVal.npy").reshape(-1, 1)
y_val = np.load("part24yVal.npy").ravel()

#valores para gráficar la curva de prediccion
x_plot = np.linspace(min(x_train.min(), x_val.min())-1,
                     max(x_train.max(), x_val.max())+1, 200).reshape(-1, 1)
plt.figure(figsize=(8,6))

# Lista de grados a probar
grados = range(1, 10)
plt.figure(figsize=(8,6))
plt.grid(True)


# Graficar puntos de entrenamiento y validación
plt.scatter(x_train, y_train, marker='x', color='blue', label='Entrenamiento')
plt.scatter(x_val, y_val, marker='o', color='red', label='Validación')

# Ejecutar en Google Colab
from google.colab import widgets
orders = range(1, 10)
tb = widgets.TabBar([str(order) for order in orders])

# Guardar resultados para escoger el mejor modelo
resultados = []

for order in orders:
    with tb.output_to(str(order), select=(order == 1)):
        # Ajuste del polinomio con numpy
        p = np.poly1d(np.polyfit(x_train, y_train, int(order)))

        # Predicciones
        y_train_pred = p(x_train)
        y_val_pred = p(x_val)
        y_plot = p(x_plot)

        # Métricas
        mse_train = mean_squared_error(y_train, y_train_pred)
        mae_train = mean_absolute_error(y_train, y_train_pred)
        mse_val = mean_squared_error(y_val, y_val_pred)
        mae_val = mean_absolute_error(y_val, y_val_pred)
        ssc = np.sum(p.c**2)   # suma de cuadrados de coeficientes

        # Guardar resultados
        resultados.append({
            "grado": order,
            "modelo": p,
            "mse_train": mse_train,
            "mae_train": mae_train,
            "mse_val": mse_val,
            "mae_val": mae_val,
            "ssc": ssc
        })

        # Gráfica
        plt.figure(figsize=(8,5))
        plt.scatter(x_train, y_train, s=40, marker='o', label='Train data')
        plt.scatter(x_val, y_val, s=40, marker='x', label='Validation')
        plt.plot(x_plot, y_plot, '-', linewidth=2, alpha=0.9, label=f'Polynomial degree {order}')
        plt.xlabel('X'); plt.ylabel('y')
        plt.title(f'Grado {order} — ajuste polinomial')
        plt.grid(alpha=0.2); plt.legend()
        plt.show()

        # Salida numérica
        print('Los coeficientes del modelo ajustado son:\n', p.c)
        print('\nEl modelo ajustado es:\n', p)
        print('\nMSE entrenamiento: {:.6f}'.format(mse_train))
        print('MSE validación:   {:.6f}'.format(mse_val))
        print('MAE entrenamiento: {:.6f}'.format(mae_train))
        print('MAE validación:   {:.6f}'.format(mae_val))
        print('SSC : {:.6f}\n'.format(ssc))

mejor_modelo = min(resultados, key=lambda x: x["mse_val"])

print("=========== MEJOR MODELO ===========")
print(f"Grado del polinomio: {mejor_modelo['grado']}")
print(f"MSE validación: {mejor_modelo['mse_val']:.6f}")
print(f"MAE validación: {mejor_modelo['mae_val']:.6f}")
print(f"SSC: {mejor_modelo['ssc']:.6f}")
print("Polinomio:\n", mejor_modelo["modelo"])

from sklearn.linear_model import Ridge, Lasso
resultados_lasso = []
alphas = np.logspace(-4, 4, 9)

for degree in grados:
    with tb.output_to(str(degree), select=(degree == 1)):
        print(f"\n===== LASSO: GRADO {degree} =====\n")
        best_record = None
        best_alpha = None

        for alpha in alphas:
            model = Lasso(alpha=alpha, max_iter=10000, random_state=0)
            pipe = Pipeline([
                ('poly', PolynomialFeatures(degree=degree, include_bias=False)),
                ('scaler', StandardScaler()),
                ('model', model)
            ])

            pipe.fit(x_train, y_train)

            y_train_pred = pipe.predict(x_train)
            y_val_pred = pipe.predict(x_val)
            y_plot_pred = pipe.predict(x_plot)

            mse_train = mean_squared_error(y_train, y_train_pred)
            mae_train = mean_absolute_error(y_train, y_train_pred)
            mse_val = mean_squared_error(y_val, y_val_pred)
            mae_val = mean_absolute_error(y_val, y_val_pred)

            coef = pipe.named_steps['model'].coef_
            ssc = np.sum(coef**2)

            record = {
                "grado": degree,
                "metodo": "Lasso",
                "alpha": alpha,
                "pipe": pipe,
                "mse_train": mse_train,
                "mae_train": mae_train,
                "mse_val": mse_val,
                "mae_val": mae_val,
                "ssc": ssc,
                "y_plot_pred": y_plot_pred
            }

            resultados_lasso.append(record)

            if (best_record is None) or (mse_val < best_record["mse_val"]):
                best_record = record
                best_alpha = alpha

        print(f"-> Lasso | mejor alpha: {best_alpha}")
        print(f"   MSE validación: {best_record['mse_val']:.6f} | MAE validación: {best_record['mae_val']:.6f} | SSC: {best_record['ssc']:.6f}")

        # Graficar (ordenando X_plot para línea suave sin modificar x_plot)
        xp = x_plot.ravel()
        order_idx = np.argsort(xp)
        plt.figure(figsize=(8,5))
        plt.scatter(x_train.ravel(), y_train, s=40, marker='o', label='Train data')
        plt.scatter(x_val.ravel(), y_val, s=40, marker='x', label='Validation')
        plt.plot(xp[order_idx], best_record['y_plot_pred'][order_idx], '-', linewidth=2, alpha=0.9, label=f'Lasso (alpha={best_alpha})')
        plt.xlabel('X'); plt.ylabel('y')
        plt.title(f'Lasso — Grado {degree} (mejor alpha={best_alpha})')
        plt.grid(alpha=0.2); plt.legend()
        plt.show()

# Mejor modelo global Lasso según MSE de validación
mejor_lasso = min(resultados_lasso, key=lambda r: r['mse_val'])
print("\n=========== MEJOR MODELO LASSO ===========")
print(f"Grado: {mejor_lasso['grado']}")
print(f"Alpha: {mejor_lasso['alpha']}")
print(f"MSE validación: {mejor_lasso['mse_val']:.6f}")
print(f"MAE validación: {mejor_lasso['mae_val']:.6f}")
print(f"SSC: {mejor_lasso['ssc']:.6f}")
print("Modelo pipeline guardado en 'mejor_lasso[\"pipe\"]'.")